{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2486696",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Exercise Image-Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5d5148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T16:47:37.010939Z",
     "start_time": "2023-04-26T16:47:37.006064Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import paths\n",
    "from datasets import VOCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "591da245-9ab5-43cc-8df2-17a5c31cd7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Image Captioning\n",
    "# Your first task will be to complete the inference code to generate captions for the given VOC dataset.\n",
    "from eval_captioning import extract_evaluate_write_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e3ce6b3-fd3d-481a-b164-e7731d3d385a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 17:02:13,511 [INFO] Running on device: cuda, cuda available: True\n",
      "2025-04-30 17:02:16,398 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-04-30 17:02:17,524 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-04-30 17:02:17,670 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-04-30 17:02:18,195 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-04-30 17:02:18,442 [INFO] Missing keys []\n",
      "2025-04-30 17:02:18,443 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-04-30 17:02:18,834 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "2025-04-30 17:02:18,876 [INFO] GPU/RAM status: RAM 6.4/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 49% UMem 2% Mem 1.1/3.0 Temp 34°C\n",
      "2025-04-30 17:02:18,877 [INFO] Output dir: outputs/eval_captioning/2025_04_30_17_02_18\n",
      "2025-04-30 17:02:22,737 [INFO] GPU/RAM status: RAM 6.4/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 99% UMem 40% Mem 1.9/3.0 Temp 42°C\n",
      "2025-04-30 17:02:22,740 [INFO] Datapoint 0 got output ['a plane on the ground at an airport', 'two trains parked on the tracks', 'a boat in the water near a dock', 'a train at a train station', 'a group of people riding bikes', 'two sheep in the grass together', 'a computer monitor and a keyboard', 'two people sitting on a train', 'a horse standing in the grass', 'a woman holding a bottle of vodka', 'a cat laying on a couch', 'two cows on the beach with the ocean in the background', 'a cow laying down in a pen', 'a cruise ship in the distance', 'a computer monitor and speakers on a desk', 'a bike parked on the side of the road']\n",
      "Captioning images: 100%|██████████| 91/91 [05:13<00:00,  3.44s/it]\n",
      "2025-04-30 17:07:32,263 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_04_30_17_02_18/pred_captions.txt\n",
      "2025-04-30 17:07:32,270 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_04_30_17_02_18/ref_captions.txt\n",
      "2025-04-30 17:07:32,276 [INFO] Evaluating captions\n",
      "2025-04-30 17:07:32,357 [INFO] BLEU 1-grams: 0.5678858282540832, 2-grams: 0.4415108475968761, 3-grams: 0.3473413509347541, 4-grams: 0.27953393436609436\n",
      "2025-04-30 17:07:32,358 [INFO] Final BLEU@4: 27.95%\n",
      "2025-04-30 17:07:32,359 [INFO] Scores: {'bleu': 0.27953393436609436}\n",
      "2025-04-30 17:07:32,359 [INFO] Writing scores to outputs/eval_captioning/2025_04_30_17_02_18/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Complete Caption Generation with Greedy Search\n",
    "\n",
    "# TODO: In file models/blip/blip_caption.py complete the methods generate and greedy_search. \n",
    "#       Generate and evaluate captions for the VOC dataset. You should get about 28% BLEU score. (2 points)\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary()\n",
    "\n",
    "extract_evaluate_write_captions(use_topk_sampling=False, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1455059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T16:47:37.256254Z",
     "start_time": "2023-04-26T16:47:37.192994Z"
    }
   },
   "outputs": [],
   "source": [
    "voc_path = Path(paths.CV_PATH_VOC)\n",
    "dataset = VOCDataset(voc_path, voc_path / \"ImageSets\" / \"Segmentation\" / \"val.txt\",\n",
    "                     load_captions=True)\n",
    "\n",
    "# load and show generated captions\n",
    "# todo update the path to match your experiment\n",
    "pred_captions_file = \"outputs/eval_captioning/2025_04_30_17_02_18/pred_captions.txt\"\n",
    "with open(pred_captions_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    pred_captions = f.readlines()\n",
    "    \n",
    "from PIL import Image\n",
    "for i in range(10):\n",
    "    data = dataset[i]\n",
    "    display(data[\"image\"])\n",
    "    print(f\"Pred caption: {pred_captions[i]}\")\n",
    "    print(f\"Reference caption: {data['caption']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eceaf88",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 17:24:59,274 [INFO] Running on device: cuda, cuda available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 17:25:02,204 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-04-30 17:25:03,322 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-04-30 17:25:03,476 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-04-30 17:25:03,956 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-04-30 17:25:04,211 [INFO] Missing keys []\n",
      "2025-04-30 17:25:04,214 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-04-30 17:25:04,601 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "2025-04-30 17:25:04,645 [INFO] GPU/RAM status: RAM 6.3/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 62% UMem 3% Mem 1.1/3.0 Temp 34°C\n",
      "2025-04-30 17:25:04,646 [INFO] Output dir: outputs/eval_captioning/2025_04_30_17_25_04\n",
      "2025-04-30 17:25:09,357 [INFO] GPU/RAM status: RAM 6.3/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 99% UMem 39% Mem 1.9/3.0 Temp 42°C\n",
      "2025-04-30 17:25:09,360 [INFO] Datapoint 0 got output ['a plane taking off at an airport possible site advice for airport operations', 'a lot of trains parked on train tracks, while each one is driving', 'boats on the water near the shore electronic wasteliderfo', 'a train at a train station at night establishment, monochromatic', 'several people on bikes racing down the street guaranteeref geographic location', \"two sheep on the grass by a tree script ='' it has\", 'a personal computer computer and headphones either side of a screen with', 'two young people sitting on a subway hips indonesia [ photo gallery', 'a white horse standing in the grass an empty playground guarantee socio', 'a girl holding a bottle of wine with a rose and hearts on it', 'a cat laying on two white chairs in a living room advice false', 'some animals laying down on the beach listed as a relaxing place to rest', 'a dog and a cow in a pen an outdoor dog boarding area', 'a cruise ship on the water script a wordpwing jp', 'a desktop computer on a wooden table separate speakers on the table', \"the bike it's parked on on the side of the street\"]\n",
      "Captioning images: 100%|██████████| 91/91 [05:58<00:00,  3.94s/it]\n",
      "2025-04-30 17:31:03,086 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_04_30_17_25_04/pred_captions.txt\n",
      "2025-04-30 17:31:03,095 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_04_30_17_25_04/ref_captions.txt\n",
      "2025-04-30 17:31:03,103 [INFO] Evaluating captions\n",
      "2025-04-30 17:31:03,198 [INFO] BLEU 1-grams: 0.2958654773384585, 2-grams: 0.17823847429228476, 3-grams: 0.109503921755735, 4-grams: 0.06796664406570305\n",
      "2025-04-30 17:31:03,199 [INFO] Final BLEU@4: 6.80%\n",
      "2025-04-30 17:31:03,199 [INFO] Scores: {'bleu': 0.06796664406570305}\n",
      "2025-04-30 17:31:03,200 [INFO] Writing scores to outputs/eval_captioning/2025_04_30_17_25_04/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Complete Caption Generation with Sampling\n",
    "# TODO: In file models/blip/blip_caption.py complete the method sampling. \n",
    "#       There, Top-K sampling instead of greedy search is used to select the next token when decoding. \n",
    "#       Evaluate again with Top-K sampling.\n",
    "#       You should get a lower BLEU score of about 7% for temperature τ = 1.0, and about 12% for τ = 0.7. \n",
    "#       Why do the results improve with lower temperature? (1 point)\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary()\n",
    "\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf0f95e-95e1-4eaf-b6c4-387268bfc237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 17:32:21,999 [INFO] Running on device: cuda, cuda available: True\n",
      "2025-04-30 17:32:24,900 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-04-30 17:32:26,032 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-04-30 17:32:26,166 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-04-30 17:32:26,659 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-04-30 17:32:26,914 [INFO] Missing keys []\n",
      "2025-04-30 17:32:26,915 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-04-30 17:32:27,237 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "2025-04-30 17:32:27,282 [INFO] GPU/RAM status: RAM 6.2/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 69% UMem 3% Mem 1.9/3.0 Temp 45°C\n",
      "2025-04-30 17:32:27,283 [INFO] Output dir: outputs/eval_captioning/2025_04_30_17_32_27\n",
      "2025-04-30 17:32:31,294 [INFO] GPU/RAM status: RAM 6.2/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 99% UMem 39% Mem 1.9/3.0 Temp 53°C\n",
      "2025-04-30 17:32:31,297 [INFO] Datapoint 0 got output ['a plane taking off at an airport possible landing jpeg georgia', 'two trains parked on train tracks tacoma, wash … regard to', 'boats on the water near the shore electronic wastelider slave', 'a train at a train station at night establishment, with graffiti on', 'a group of people riding bikes letters anecdotes backwards', 'two sheep on the grass by a tree scripticial and', 'a room with a desk, computer, laptop, and other computer equipment', 'two people who are sitting at a table muteels are smiling', 'a white horse standing in the grass an empty playground guarantee socio', 'a girl holding a bottle of liquor with a red lid device in her', 'a cat laying on a couch using a computer an a laptop', 'some animals laying down on the beach listed as a relaxing place to rest', 'a cow laying down on the ground lettering is white null with', 'a cruise ship on the water scripting my video sort of', 'a desktop computer on a desk – electronic equipment on a table', 'the bike parked by the curb establishment itself socio - urban photography']\n",
      "Captioning images: 100%|██████████| 91/91 [05:34<00:00,  3.67s/it]\n",
      "2025-04-30 17:38:01,561 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_04_30_17_32_27/pred_captions.txt\n",
      "2025-04-30 17:38:01,567 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_04_30_17_32_27/ref_captions.txt\n",
      "2025-04-30 17:38:01,573 [INFO] Evaluating captions\n",
      "2025-04-30 17:38:01,658 [INFO] BLEU 1-grams: 0.3706788287394824, 2-grams: 0.25056410716115096, 3-grams: 0.17011063007177826, 4-grams: 0.11746480761753343\n",
      "2025-04-30 17:38:01,658 [INFO] Final BLEU@4: 11.75%\n",
      "2025-04-30 17:38:01,659 [INFO] Scores: {'bleu': 0.11746480761753343}\n",
      "2025-04-30 17:38:01,660 [INFO] Writing scores to outputs/eval_captioning/2025_04_30_17_32_27/scores.json\n"
     ]
    }
   ],
   "source": [
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b4abaff-6d80-43dc-9e2f-4377b09548b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 20:28:21,017 [INFO] Running on device: cuda, cuda available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 20:28:23,997 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-02 20:28:25,217 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-02 20:28:25,365 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-02 20:28:25,889 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-02 20:28:26,134 [INFO] Missing keys []\n",
      "2025-05-02 20:28:26,135 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-05-02 20:28:26,437 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "2025-05-02 20:28:26,479 [INFO] GPU/RAM status: RAM 5.7/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 70% UMem 3% Mem 2.0/3.0 Temp 52°C\n",
      "2025-05-02 20:28:26,480 [INFO] Output dir: outputs/eval_captioning/2025_05_02_20_28_26\n",
      "2025-05-02 20:28:29,429 [INFO] GPU/RAM status: RAM 5.7/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 99% UMem 41% Mem 2.0/3.0 Temp 58°C\n",
      "2025-05-02 20:28:29,432 [INFO] Datapoint 0 got output ['a plane waiting at an airport transmitter', 'two trains parked on a track opened', 'boats on the water in the city guarantee', 'a train at a train station at night', 'a group of men riding bikes unidentified', 'two sheep on the grass eating the grass', 'a desktop computer with blue glow mean in', 'two people that are sitting at the table', 'a kid playing with a pony surfing', 'a woman holding up a bottle of wine', 'a cat that is lying on a chair', 'cows at the beach eating and drinking bays', 'a cow laying down on the ground animals', 'a cruise ship and palm trees mls', 'a desktop computer with a keyboard guarantee', 'some bikes parked by a wall - light']\n",
      "Captioning images: 100%|██████████| 91/91 [05:15<00:00,  3.47s/it]\n",
      "2025-05-02 20:33:42,446 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_02_20_28_26/pred_captions.txt\n",
      "2025-05-02 20:33:42,497 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_02_20_28_26/ref_captions.txt\n",
      "2025-05-02 20:33:42,503 [INFO] Evaluating captions\n",
      "2025-05-02 20:33:42,625 [INFO] BLEU 1-grams: 0.4191557451996023, 2-grams: 0.28535191543309746, 3-grams: 0.1942143017306638, 4-grams: 0.1358436749630613\n",
      "2025-05-02 20:33:42,626 [INFO] Final BLEU@4: 13.58%\n",
      "2025-05-02 20:33:42,627 [INFO] Scores: {'bleu': 0.1358436749630613}\n",
      "2025-05-02 20:33:42,627 [INFO] Writing scores to outputs/eval_captioning/2025_05_02_20_28_26/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Prompt Engineering\n",
    "# TODO: Experiment with different prompts (the default prompt is “a picture of ”). \n",
    "#       Can you improve the BLEU score? Try at least 3 new settings.\n",
    "#       Note the prompt and the resulting BLEU score in a table for each setting. \n",
    "#       Add the table to your report. (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=0.7, prompt=\"an image of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b998df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 20:35:34,287 [INFO] Running on device: cuda, cuda available: True\n",
      "2025-05-02 20:35:37,611 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-02 20:35:38,862 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-02 20:35:39,141 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-02 20:35:48,874 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-02 20:35:49,123 [INFO] Missing keys []\n",
      "2025-05-02 20:35:49,124 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-05-02 20:35:49,477 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "2025-05-02 20:35:49,526 [INFO] GPU/RAM status: RAM 5.0/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 48% UMem 2% Mem 2.0/3.0 Temp 41°C\n",
      "2025-05-02 20:35:49,527 [INFO] Output dir: outputs/eval_captioning/2025_05_02_20_35_49\n",
      "2025-05-02 20:35:54,316 [INFO] GPU/RAM status: RAM 5.0/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 40% Mem 2.0/3.0 Temp 50°C\n",
      "2025-05-02 20:35:54,319 [INFO] Datapoint 0 got output ['a plane taking off at an airport ranked backwards malaga airport script — only', 'two trains parked on train tracks null, on a sunny day a blue shed is', 'boats docked on a river in the country tilly piers park establishment malaga', 'a train at a train station at nightgenpw lonely georgia station slave', 'two men riding bikes on a track mechanical track phones … mechanical track bike racing', 'two sheep on a field of grass only one is sitting and one sheep is laying down', 'a desk with a desktop and a laptop with a computer monitor that has two monitors on it', 'two young people sitting on a subway mechanical phoneselsgame robotic arm', 'a brown and white horse in a field —, the horse is about to fall', 'a woman holding a bottle of liquor with a red lid jpg 歌', 'a living room with green walls talks to a cat on the couch a table and a', 'some cows that are laying down either side of the ocean - another cow laying down on', 'a cow laying down on the ground her head resting on a pile of straw its head', 'a cruise ship on the water script script transmittercoming to a cruise ship', 'a desktop computer with a monitor motion sensor jpeg odd shaped speaker 歌 手', 'some bikes parked by a wall itself 歌 手 till i die i will']\n",
      "Captioning images: 100%|██████████| 91/91 [05:38<00:00,  3.72s/it]\n",
      "2025-05-02 20:41:27,791 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_02_20_35_49/pred_captions.txt\n",
      "2025-05-02 20:41:27,797 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_02_20_35_49/ref_captions.txt\n",
      "2025-05-02 20:41:27,802 [INFO] Evaluating captions\n",
      "2025-05-02 20:41:27,896 [INFO] BLEU 1-grams: 0.3748414235160329, 2-grams: 0.25261199048705046, 3-grams: 0.1714516905758642, 4-grams: 0.1197692817375619\n",
      "2025-05-02 20:41:27,896 [INFO] Final BLEU@4: 11.98%\n",
      "2025-05-02 20:41:27,897 [INFO] Scores: {'bleu': 0.1197692817375619}\n",
      "2025-05-02 20:41:27,898 [INFO] Writing scores to outputs/eval_captioning/2025_05_02_20_35_49/scores.json\n"
     ]
    }
   ],
   "source": [
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=0.7, prompt=\"a photo of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d567b5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 20:41:41,079 [INFO] Running on device: cuda, cuda available: True\n",
      "2025-05-02 20:41:43,912 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-02 20:41:45,048 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-02 20:41:45,190 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-02 20:41:45,777 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-02 20:41:46,042 [INFO] Missing keys []\n",
      "2025-05-02 20:41:46,043 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-05-02 20:41:46,348 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "2025-05-02 20:41:46,389 [INFO] GPU/RAM status: RAM 4.8/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 70% UMem 3% Mem 2.0/3.0 Temp 64°C\n",
      "2025-05-02 20:41:46,390 [INFO] Output dir: outputs/eval_captioning/2025_05_02_20_41_46\n",
      "2025-05-02 20:41:50,248 [INFO] GPU/RAM status: RAM 4.8/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 99% UMem 40% Mem 2.0/3.0 Temp 69°C\n",
      "2025-05-02 20:41:50,252 [INFO] Datapoint 0 got output ['a plane with a lift on the top [ photo taken at an', 'a pair of trains at a station mechanical engineering is needed to build', 'the canal outside of the oxford university campus on the oxford union river', 'a train at a train station at night – black and white', 'a group of cyclists racing down the track sort of guaranteeing', 'two sheep on a field of grass either green or white,', 'a remote control and computer room phones gazette mean regard', 'a young couple on a metro nullpw lonelytime', 'a little pony in a park something very odd with a green', 'a woman holding a bottle of gin with a red design on it', 'a living room with green walls device and furniture odd looking objects', 'cows resting in the sand on the beach sporting others in', 'a cow laying down on the ground phones are placed next to it', 'a cruise ship on the water its sinking off the coast of miami', 'a desktop computer with a pair of headphones dull on it', 'bike in the dark with light trails opener in the background']\n",
      "Captioning images: 100%|██████████| 91/91 [05:47<00:00,  3.82s/it]\n",
      "2025-05-02 20:47:33,616 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_02_20_41_46/pred_captions.txt\n",
      "2025-05-02 20:47:33,621 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_02_20_41_46/ref_captions.txt\n",
      "2025-05-02 20:47:33,627 [INFO] Evaluating captions\n",
      "2025-05-02 20:47:33,720 [INFO] BLEU 1-grams: 0.352535004155722, 2-grams: 0.23345201845542726, 3-grams: 0.15584359263415037, 4-grams: 0.10692294680197675\n",
      "2025-05-02 20:47:33,721 [INFO] Final BLEU@4: 10.69%\n",
      "2025-05-02 20:47:33,724 [INFO] Scores: {'bleu': 0.10692294680197675}\n",
      "2025-05-02 20:47:33,724 [INFO] Writing scores to outputs/eval_captioning/2025_05_02_20_41_46/scores.json\n"
     ]
    }
   ],
   "source": [
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=0.7, prompt=\"an image showing \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a352c828-0517-482d-a607-278accb7c559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 20:49:37,608 [INFO] Running on device: cuda, cuda available: True\n",
      "2025-05-02 20:49:40,522 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-02 20:49:41,655 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-02 20:49:41,811 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-02 20:49:42,403 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-02 20:49:42,672 [INFO] Missing keys []\n",
      "2025-05-02 20:49:42,673 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-05-02 20:49:43,012 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "2025-05-02 20:49:43,061 [INFO] GPU/RAM status: RAM 4.8/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 64% UMem 3% Mem 2.0/3.0 Temp 41°C\n",
      "2025-05-02 20:49:43,062 [INFO] Output dir: outputs/eval_captioning/2025_05_02_20_49_43\n",
      "2025-05-02 20:49:46,486 [INFO] GPU/RAM status: RAM 4.8/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 40% Mem 2.0/3.0 Temp 49°C\n",
      "2025-05-02 20:49:46,489 [INFO] Datapoint 0 got output ['a plane waiting at an airport transmitterbard piers', 'two trains on the tracks in the woods avatar in', 'a boat in the water near some treeslide _', 'a train going down the tracks 歌 possible', 'three people competing in a bike race rude or rude?', 'two sheep laying in the grass an adult sheep is lying', 'a desktop computer set up with a keyboard and a monitor', 'a man and a woman smiling at the camera swat', 'a horse with a green gate with a slide in it', 'a woman holding a bottle of vodka synthetic georgia', 'a living room setting with two chairs and a cat celestial', 'two cows sitting on the beach possible on the beach', 'a cow laying down in the hay papers at an', 'the cruise ship that is in the water others are riding', 'a computer desk with a monitor and a keyboard, sitting', 'a bike parked by a building, at night socio']\n",
      "Captioning images: 100%|██████████| 91/91 [05:08<00:00,  3.39s/it]\n",
      "2025-05-02 20:54:51,274 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_02_20_49_43/pred_captions.txt\n",
      "2025-05-02 20:54:51,280 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_02_20_49_43/ref_captions.txt\n",
      "2025-05-02 20:54:51,286 [INFO] Evaluating captions\n",
      "2025-05-02 20:54:51,368 [INFO] BLEU 1-grams: 0.40898727660510337, 2-grams: 0.2749227502446929, 3-grams: 0.18641570712042801, 4-grams: 0.12985478339686324\n",
      "2025-05-02 20:54:51,369 [INFO] Final BLEU@4: 12.99%\n",
      "2025-05-02 20:54:51,370 [INFO] Scores: {'bleu': 0.12985478339686324}\n",
      "2025-05-02 20:54:51,370 [INFO] Writing scores to outputs/eval_captioning/2025_05_02_20_49_43/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.4 Student Hyperparameter Search\n",
    "# TODO: Experiment with different decoding parameters. (Top-K with different K and temperature or greedy decoding). \n",
    "#       Can you improve the BLEU score? Try at least 3 new settings.\n",
    "#       Note the hyperparameters, the prompt and the resulting BLEU score in a table for each setting.\n",
    "#       Add the table to your report. (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=30, temperature=0.7, prompt=\"an image of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b6d56c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 20:55:06,307 [INFO] Running on device: cuda, cuda available: True\n",
      "2025-05-02 20:55:09,188 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-02 20:55:10,296 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-02 20:55:10,456 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-02 20:55:10,959 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-02 20:55:11,210 [INFO] Missing keys []\n",
      "2025-05-02 20:55:11,210 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-05-02 20:55:11,508 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "2025-05-02 20:55:11,547 [INFO] GPU/RAM status: RAM 4.9/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 71% UMem 3% Mem 2.0/3.0 Temp 63°C\n",
      "2025-05-02 20:55:11,548 [INFO] Output dir: outputs/eval_captioning/2025_05_02_20_55_11\n",
      "2025-05-02 20:55:14,836 [INFO] GPU/RAM status: RAM 4.9/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 99% UMem 39% Mem 2.0/3.0 Temp 69°C\n",
      "2025-05-02 20:55:14,838 [INFO] Datapoint 0 got output ['a plane waiting at an airport transmitter – in', 'two trains sitting side by side backwards possible to', 'a boat in the water by a dock basin', 'a train going down a track in the night', 'the bicycle race on a bike track guarantee slave', 'two animals that are laying down bays piers', 'a computer in a room with a keyboard and monitor', 'a couple that are sitting together weddings others', 'a horse playing on a playground taken from top view', 'a woman that is holding a bottle corresponding bottle', 'a cat that is laying in a chair pet room', 'two cows laying on the beach asking to feed', 'a cow that is in the hay donna newspapers', 'a cruise ship from the inside bestsellers indonesia', 'a computer desk with a computer monitor and speakers -', 'a bike parked on the side of the road roadway']\n",
      "Captioning images: 100%|██████████| 91/91 [05:07<00:00,  3.38s/it]\n",
      "2025-05-02 21:00:19,022 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_02_20_55_11/pred_captions.txt\n",
      "2025-05-02 21:00:19,028 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_02_20_55_11/ref_captions.txt\n",
      "2025-05-02 21:00:19,034 [INFO] Evaluating captions\n",
      "2025-05-02 21:00:19,120 [INFO] BLEU 1-grams: 0.41110115045566925, 2-grams: 0.2779957621349106, 3-grams: 0.18898458528114778, 4-grams: 0.13203476358921354\n",
      "2025-05-02 21:00:19,121 [INFO] Final BLEU@4: 13.20%\n",
      "2025-05-02 21:00:19,122 [INFO] Scores: {'bleu': 0.13203476358921354}\n",
      "2025-05-02 21:00:19,122 [INFO] Writing scores to outputs/eval_captioning/2025_05_02_20_55_11/scores.json\n"
     ]
    }
   ],
   "source": [
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=80, temperature=0.7, prompt=\"an image of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94bf535e-447d-4493-bd4f-e12731007a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 21:08:59,334 [INFO] Running on device: cuda, cuda available: True\n",
      "2025-05-02 21:09:02,187 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-02 21:09:03,300 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-02 21:09:03,449 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-02 21:09:03,972 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-02 21:09:04,210 [INFO] Missing keys []\n",
      "2025-05-02 21:09:04,211 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-05-02 21:09:04,510 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "2025-05-02 21:09:04,549 [INFO] GPU/RAM status: RAM 4.9/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 69% UMem 3% Mem 2.0/3.0 Temp 39°C\n",
      "2025-05-02 21:09:04,550 [INFO] Output dir: outputs/eval_captioning/2025_05_02_21_09_04\n",
      "2025-05-02 21:09:07,966 [INFO] GPU/RAM status: RAM 5.0/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 99% UMem 40% Mem 2.0/3.0 Temp 48°C\n",
      "2025-05-02 21:09:07,970 [INFO] Datapoint 0 got output ['a plane at the airport terminal [ photo by @ mike', 'two trains parked on the tracks on a train track', 'a boat in the water near a dock fredrikstad', 'a train that is parked at a station itself celestial', 'a group of cyclists racing down a track mystical either', 'two sheep laying in the grass advice desktop wallpaper', 'a computer with a blue wave on the screen with a', 'two people that are sitting down peat others are sitting', 'a horse that is standing in the grass lettering script', 'a woman holding up a bottle staten island vodka', 'a cat that is laying on a couchhopping', 'two cows on the beach with the ocean in the background', 'a cow laying down in the hay swear donna', 'a cruise ship in the distance null electronic and', 'a computer desk with a computer monitor — and a pair', 'a bike parked on the side of the road roadway']\n",
      "Captioning images: 100%|██████████| 91/91 [05:11<00:00,  3.42s/it]\n",
      "2025-05-02 21:14:16,088 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_02_21_09_04/pred_captions.txt\n",
      "2025-05-02 21:14:16,104 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_02_21_09_04/ref_captions.txt\n",
      "2025-05-02 21:14:16,118 [INFO] Evaluating captions\n",
      "2025-05-02 21:14:16,209 [INFO] BLEU 1-grams: 0.49144158291453427, 2-grams: 0.3676863355295101, 3-grams: 0.276722312750553, 4-grams: 0.21162194958179523\n",
      "2025-05-02 21:14:16,209 [INFO] Final BLEU@4: 21.16%\n",
      "2025-05-02 21:14:16,210 [INFO] Scores: {'bleu': 0.21162194958179523}\n",
      "2025-05-02 21:14:16,211 [INFO] Writing scores to outputs/eval_captioning/2025_05_02_21_09_04/scores.json\n"
     ]
    }
   ],
   "source": [
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=80, temperature=0.2, prompt=\"an image of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f0cb7-6677-49ed-be36-1891dae6e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Image-Text Retrieval\n",
    "# Your second task will be to train and evaluate the retrieval head of the BLIP model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d87144-6833-4d58-ac2b-9bc8f4e69119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 19:04:29,019 [INFO] Running on device: cuda, cuda available: True\n",
      "2025-05-02 19:04:32,135 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2025-05-02 19:04:32,447 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2025-05-02 19:04:45,755 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-02 19:04:46,012 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2025-05-02 19:04:46,013 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-05-02 19:04:46,153 [INFO] Done loading retrieval head from /home/lmb/dllab2025s/public/ckpt/blip_model_retrieval_head.pth\n",
      "2025-05-02 19:04:46,779 [INFO] GPU/RAM status: RAM 4.4/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 30% UMem 1% Mem 1.1/3.0 Temp 31°C\n",
      "2025-05-02 19:04:46,783 [INFO] Output dir: outputs/eval_retrieval/2025_05_02_19_04_46\n",
      "2025-05-02 19:04:46,783 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:42<00:00,  1.79s/it]\n",
      "2025-05-02 19:07:29,735 [INFO] Validation results: {'i_r1': 0.5341614906832298, 'i_r5': 0.8102139406487232, 'i_r10': 0.9047619047619048, 'i_medr': np.float64(1.0), 'i_meanr': np.float64(4.076604554865424), 't_r1': 0.5355417529330573, 't_r5': 0.8184955141476881, 't_r10': 0.8923395445134575, 't_medr': np.float64(1.0), 't_meanr': np.float64(4.680469289164941)}\n",
      "2025-05-02 19:07:29,736 [INFO] Max GPU memory allocated: 1591.402M\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Complete Forward Pass and Evaluate\n",
    "#     Todo: Complete the forward pass in file models/blip/blip_retrieval.py. \n",
    "#           Evaluate your implementation with the provided checkpoint. \n",
    "#           You should get about 54% image-to-text R@1. (2 points)\n",
    "from eval_retrieval import eval_without_args    \n",
    "eval_without_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d448da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_retrieval import train_retrieval_without_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d4778a-aa46-4933-95c0-98b66b697bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 17:51:28,784 [INFO] Running on device: cuda, cuda available: True\n",
      "2025-04-30 17:51:31,683 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2025-04-30 17:51:31,770 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2025-04-30 17:51:32,269 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-04-30 17:51:32,503 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2025-04-30 17:51:32,504 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-04-30 17:51:32,804 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2025-04-30 17:51:32,804 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2025-04-30 17:51:32,805 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2025-04-30 17:51:32,805 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2025-04-30 17:51:32,806 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "2025-04-30 17:51:32,927 [INFO] GPU/RAM status: RAM 6.7/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 24% UMem 1% Mem 1.9/3.0 Temp 53°C\n",
      "2025-04-30 17:51:32,931 [INFO] Output dir: outputs/train_retrieval/2025_04_30_17_51_32\n",
      "2025-04-30 17:51:32,938 [INFO] Training epoch 0\n",
      "2025-04-30 17:51:37,369 [INFO]   step: 0 loss: 2.756 lr: 1.000e-03\n",
      "Training:   0%|          | 0/91 [00:04<?, ?it/s]2025-04-30 17:51:37,380 [INFO] GPU/RAM status: RAM 6.7/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 0% UMem 0% Mem 1.9/3.0 Temp 54°C\n",
      "Training:   3%|▎         | 3/91 [00:09<04:05,  2.79s/it]/project/dl2025s/biswass/exercise/models/preprocessing/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative\n",
      "  offset = -low * scale\n",
      "2025-04-30 17:52:00,551 [INFO]   step: 10 loss: 1.204 lr: 9.780e-04\n",
      "2025-04-30 17:52:24,218 [INFO]   step: 20 loss: 0.463 lr: 9.560e-04\n",
      "2025-04-30 17:52:47,590 [INFO]   step: 30 loss: 0.673 lr: 9.341e-04\n",
      "2025-04-30 17:53:11,538 [INFO]   step: 40 loss: 0.455 lr: 9.121e-04\n",
      "2025-04-30 17:53:34,807 [INFO]   step: 50 loss: 0.222 lr: 8.901e-04\n",
      "Training:  55%|█████▍    | 50/91 [02:01<01:35,  2.32s/it]2025-04-30 17:53:34,811 [INFO] GPU/RAM status: RAM 6.7/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 42% Mem 1.9/3.0 Temp 67°C\n",
      "2025-04-30 17:53:58,071 [INFO]   step: 60 loss: 0.352 lr: 8.681e-04\n",
      "2025-04-30 17:54:20,295 [INFO]   step: 70 loss: 0.253 lr: 8.462e-04\n",
      "2025-04-30 17:54:44,679 [INFO]   step: 80 loss: 0.211 lr: 8.242e-04\n",
      "2025-04-30 17:55:08,251 [INFO]   step: 90 loss: 0.244 lr: 8.022e-04\n",
      "Training: 100%|██████████| 91/91 [03:35<00:00,  2.30s/it]2025-04-30 17:55:08,256 [INFO] Max GPU memory allocated: 1686.658M\n",
      "Training: 100%|██████████| 91/91 [03:35<00:00,  2.37s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:22<00:00,  1.56s/it]\n",
      "2025-04-30 17:57:30,559 [INFO] Validation results: {'i_r1': 0.3305728088336784, 'i_r5': 0.6494133885438234, 'i_r10': 0.7784679089026915, 'i_medr': np.float64(3.0), 'i_meanr': np.float64(9.496204278812975), 't_r1': 0.33126293995859213, 't_r5': 0.6438923395445134, 't_r10': 0.7674258109040718, 't_medr': np.float64(3.0), 't_meanr': np.float64(9.285714285714286)}\n",
      "2025-04-30 17:57:30,609 [INFO] Training epoch 1\n",
      "2025-04-30 17:57:32,233 [INFO]   step: 0 loss: 0.364 lr: 8.000e-04\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-04-30 17:57:32,237 [INFO] GPU/RAM status: RAM 6.7/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 37% Mem 1.9/3.0 Temp 72°C\n",
      "2025-04-30 17:57:47,737 [INFO]   step: 10 loss: 0.183 lr: 7.780e-04\n",
      "2025-04-30 17:58:03,221 [INFO]   step: 20 loss: 0.263 lr: 7.560e-04\n",
      "2025-04-30 17:58:18,655 [INFO]   step: 30 loss: 0.228 lr: 7.341e-04\n",
      "2025-04-30 17:58:34,173 [INFO]   step: 40 loss: 0.186 lr: 7.121e-04\n",
      "2025-04-30 17:58:49,664 [INFO]   step: 50 loss: 0.101 lr: 6.901e-04\n",
      "Training:  55%|█████▍    | 50/91 [01:19<01:03,  1.54s/it]2025-04-30 17:58:49,669 [INFO] GPU/RAM status: RAM 6.7/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 41% Mem 1.9/3.0 Temp 72°C\n",
      "2025-04-30 17:59:05,245 [INFO]   step: 60 loss: 0.418 lr: 6.681e-04\n",
      "2025-04-30 17:59:20,948 [INFO]   step: 70 loss: 0.085 lr: 6.462e-04\n",
      "2025-04-30 17:59:36,520 [INFO]   step: 80 loss: 0.140 lr: 6.242e-04\n",
      "2025-04-30 17:59:52,095 [INFO]   step: 90 loss: 0.186 lr: 6.022e-04\n",
      "Training: 100%|██████████| 91/91 [02:21<00:00,  1.57s/it]2025-04-30 17:59:52,099 [INFO] Max GPU memory allocated: 1686.658M\n",
      "Training: 100%|██████████| 91/91 [02:21<00:00,  1.55s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:22<00:00,  1.57s/it]\n",
      "2025-04-30 18:02:15,112 [INFO] Validation results: {'i_r1': 0.378191856452726, 'i_r5': 0.6894409937888198, 'i_r10': 0.8150448585231194, 'i_medr': np.float64(2.0), 'i_meanr': np.float64(7.477570738440304), 't_r1': 0.36645962732919257, 't_r5': 0.6880607315389924, 't_r10': 0.8178053830227743, 't_medr': np.float64(2.0), 't_meanr': np.float64(7.521048999309869)}\n",
      "2025-04-30 18:02:15,148 [INFO] Training epoch 2\n",
      "2025-04-30 18:02:16,775 [INFO]   step: 0 loss: 0.102 lr: 6.000e-04\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-04-30 18:02:16,779 [INFO] GPU/RAM status: RAM 6.7/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 38% Mem 1.9/3.0 Temp 71°C\n",
      "2025-04-30 18:02:32,317 [INFO]   step: 10 loss: 0.269 lr: 5.780e-04\n",
      "2025-04-30 18:02:48,123 [INFO]   step: 20 loss: 0.146 lr: 5.560e-04\n",
      "2025-04-30 18:03:03,870 [INFO]   step: 30 loss: 0.117 lr: 5.341e-04\n",
      "2025-04-30 18:03:19,326 [INFO]   step: 40 loss: 0.267 lr: 5.121e-04\n",
      "2025-04-30 18:03:34,806 [INFO]   step: 50 loss: 0.187 lr: 4.901e-04\n",
      "Training:  55%|█████▍    | 50/91 [01:19<01:03,  1.55s/it]2025-04-30 18:03:34,810 [INFO] GPU/RAM status: RAM 6.7/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 99% UMem 38% Mem 1.9/3.0 Temp 71°C\n",
      "2025-04-30 18:03:50,807 [INFO]   step: 60 loss: 0.205 lr: 4.681e-04\n",
      "2025-04-30 18:04:06,642 [INFO]   step: 70 loss: 0.259 lr: 4.462e-04\n",
      "2025-04-30 18:04:22,159 [INFO]   step: 80 loss: 0.095 lr: 4.242e-04\n",
      "2025-04-30 18:04:37,761 [INFO]   step: 90 loss: 0.134 lr: 4.022e-04\n",
      "Training: 100%|██████████| 91/91 [02:22<00:00,  1.56s/it]2025-04-30 18:04:37,766 [INFO] Max GPU memory allocated: 1686.658M\n",
      "Training: 100%|██████████| 91/91 [02:22<00:00,  1.57s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:22<00:00,  1.57s/it]\n",
      "2025-04-30 18:07:00,942 [INFO] Validation results: {'i_r1': 0.4209799861973775, 'i_r5': 0.7412008281573499, 'i_r10': 0.8592132505175983, 'i_medr': np.float64(2.0), 'i_meanr': np.float64(6.545893719806763), 't_r1': 0.38923395445134573, 't_r5': 0.7004830917874396, 't_r10': 0.8184955141476881, 't_medr': np.float64(2.0), 't_meanr': np.float64(7.115942028985507)}\n",
      "2025-04-30 18:07:00,975 [INFO] Training epoch 3\n",
      "2025-04-30 18:07:02,557 [INFO]   step: 0 loss: 0.108 lr: 4.000e-04\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-04-30 18:07:02,560 [INFO] GPU/RAM status: RAM 6.7/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 38% Mem 1.9/3.0 Temp 71°C\n",
      "2025-04-30 18:07:18,080 [INFO]   step: 10 loss: 0.188 lr: 3.780e-04\n",
      "2025-04-30 18:07:33,640 [INFO]   step: 20 loss: 0.192 lr: 3.560e-04\n",
      "2025-04-30 18:07:49,145 [INFO]   step: 30 loss: 0.046 lr: 3.341e-04\n",
      "2025-04-30 18:08:04,680 [INFO]   step: 40 loss: 0.113 lr: 3.121e-04\n",
      "2025-04-30 18:08:20,143 [INFO]   step: 50 loss: 0.094 lr: 2.901e-04\n",
      "Training:  55%|█████▍    | 50/91 [01:19<01:03,  1.54s/it]2025-04-30 18:08:20,147 [INFO] GPU/RAM status: RAM 6.7/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 40% Mem 1.9/3.0 Temp 71°C\n",
      "2025-04-30 18:08:35,637 [INFO]   step: 60 loss: 0.247 lr: 2.681e-04\n",
      "2025-04-30 18:08:51,159 [INFO]   step: 70 loss: 0.178 lr: 2.462e-04\n",
      "2025-04-30 18:09:06,724 [INFO]   step: 80 loss: 0.147 lr: 2.242e-04\n",
      "2025-04-30 18:09:22,240 [INFO]   step: 90 loss: 0.058 lr: 2.022e-04\n",
      "Training: 100%|██████████| 91/91 [02:21<00:00,  1.56s/it]2025-04-30 18:09:22,246 [INFO] Max GPU memory allocated: 1686.658M\n",
      "Training: 100%|██████████| 91/91 [02:21<00:00,  1.55s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:22<00:00,  1.56s/it]\n",
      "2025-04-30 18:11:44,445 [INFO] Validation results: {'i_r1': 0.42374051069703245, 'i_r5': 0.7543133195307108, 'i_r10': 0.865424430641822, 'i_medr': np.float64(2.0), 'i_meanr': np.float64(5.98343685300207), 't_r1': 0.4085576259489303, 't_r5': 0.728088336783989, 't_r10': 0.8454106280193237, 't_medr': np.float64(2.0), 't_meanr': np.float64(6.506556245686681)}\n",
      "2025-04-30 18:11:44,479 [INFO] Training epoch 4\n",
      "2025-04-30 18:11:46,048 [INFO]   step: 0 loss: 0.044 lr: 2.000e-04\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-04-30 18:11:46,053 [INFO] GPU/RAM status: RAM 6.8/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 42% Mem 1.9/3.0 Temp 71°C\n",
      "2025-04-30 18:12:01,536 [INFO]   step: 10 loss: 0.221 lr: 1.780e-04\n",
      "2025-04-30 18:12:17,088 [INFO]   step: 20 loss: 0.137 lr: 1.560e-04\n",
      "2025-04-30 18:12:32,572 [INFO]   step: 30 loss: 0.149 lr: 1.341e-04\n",
      "2025-04-30 18:12:48,119 [INFO]   step: 40 loss: 0.109 lr: 1.121e-04\n",
      "2025-04-30 18:13:03,653 [INFO]   step: 50 loss: 0.129 lr: 9.011e-05\n",
      "Training:  55%|█████▍    | 50/91 [01:19<01:03,  1.56s/it]2025-04-30 18:13:03,657 [INFO] GPU/RAM status: RAM 6.8/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 38% Mem 1.9/3.0 Temp 71°C\n",
      "2025-04-30 18:13:19,192 [INFO]   step: 60 loss: 0.241 lr: 6.813e-05\n",
      "2025-04-30 18:13:34,720 [INFO]   step: 70 loss: 0.138 lr: 4.615e-05\n",
      "2025-04-30 18:13:50,276 [INFO]   step: 80 loss: 0.044 lr: 2.418e-05\n",
      "2025-04-30 18:14:05,832 [INFO]   step: 90 loss: 0.170 lr: 2.198e-06\n",
      "Training: 100%|██████████| 91/91 [02:21<00:00,  1.57s/it]2025-04-30 18:14:05,837 [INFO] Max GPU memory allocated: 1686.658M\n",
      "Training: 100%|██████████| 91/91 [02:21<00:00,  1.55s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:22<00:00,  1.56s/it]\n",
      "2025-04-30 18:16:28,275 [INFO] Validation results: {'i_r1': 0.4354727398205659, 'i_r5': 0.7550034506556246, 'i_r10': 0.8681849551414769, 'i_medr': np.float64(2.0), 'i_meanr': np.float64(5.772256728778468), 't_r1': 0.4147688060731539, 't_r5': 0.7301587301587301, 't_r10': 0.8502415458937198, 't_medr': np.float64(2.0), 't_meanr': np.float64(6.384403036576949)}\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Complete Loss and Train from Scratch\n",
    "# Todo: Complete the loss computation in file train_retrieval.py function train_epoch. \n",
    "#       Train the retrieval projection layers from scratch (i.e. from random initialization).\n",
    "#       You should get about 43% image-to-text R@1. (1 point)\n",
    "train_retrieval_without_args(finetune=False, learning_rate=1e-3, weight_decay=1e-3, epochs=5, temperature=0.1)\n",
    "\n",
    "# Optional: start a tensorboard server tensorboard --logdir outputs --port 6006 and watch the experiment in the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dadb532e-65e3-4e24-8fa9-2a26e3ea6a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 19:11:45,691 [INFO] Running on device: cuda, cuda available: True\n",
      "2025-05-02 19:11:48,578 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2025-05-02 19:11:48,658 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2025-05-02 19:11:49,187 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-02 19:11:49,414 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2025-05-02 19:11:49,415 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-05-02 19:11:49,440 [INFO] Done loading retrieval head from /home/lmb/dllab2025s/public/ckpt/blip_model_retrieval_head.pth\n",
      "2025-05-02 19:11:49,715 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-02 19:11:49,716 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2025-05-02 19:11:49,717 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-02 19:11:49,717 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2025-05-02 19:11:49,719 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "2025-05-02 19:11:49,827 [INFO] GPU/RAM status: RAM 4.7/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 50% UMem 2% Mem 1.8/3.0 Temp 36°C\n",
      "2025-05-02 19:11:49,830 [INFO] Output dir: outputs/train_retrieval/2025_05_02_19_11_49\n",
      "2025-05-02 19:11:49,837 [INFO] Training epoch 0\n",
      "2025-05-02 19:11:54,249 [INFO]   step: 0 loss: 1.559 lr: 1.000e-05\n",
      "Training:   0%|          | 0/91 [00:04<?, ?it/s]2025-05-02 19:11:54,258 [INFO] GPU/RAM status: RAM 4.8/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 0% UMem 0% Mem 1.8/3.0 Temp 38°C\n",
      "Training:   4%|▍         | 4/91 [00:11<03:40,  2.53s/it]/project/dl2025s/biswass/exercise/models/preprocessing/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative\n",
      "  offset = -low * scale\n",
      "2025-05-02 19:12:15,402 [INFO]   step: 10 loss: 1.566 lr: 9.634e-06\n",
      "2025-05-02 19:12:36,429 [INFO]   step: 20 loss: 1.567 lr: 9.267e-06\n",
      "2025-05-02 19:12:57,594 [INFO]   step: 30 loss: 1.680 lr: 8.901e-06\n",
      "2025-05-02 19:13:18,912 [INFO]   step: 40 loss: 1.561 lr: 8.535e-06\n",
      "2025-05-02 19:13:40,115 [INFO]   step: 50 loss: 1.433 lr: 8.168e-06\n",
      "Training:  55%|█████▍    | 50/91 [01:50<01:29,  2.19s/it]2025-05-02 19:13:40,119 [INFO] GPU/RAM status: RAM 4.9/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 41% Mem 1.8/3.0 Temp 65°C\n",
      "2025-05-02 19:14:01,302 [INFO]   step: 60 loss: 1.526 lr: 7.802e-06\n",
      "2025-05-02 19:14:22,392 [INFO]   step: 70 loss: 1.513 lr: 7.436e-06\n",
      "2025-05-02 19:14:42,252 [INFO]   step: 80 loss: 1.534 lr: 7.070e-06\n",
      "2025-05-02 19:15:01,529 [INFO]   step: 90 loss: 1.252 lr: 6.703e-06\n",
      "Training: 100%|██████████| 91/91 [03:11<00:00,  2.04s/it]2025-05-02 19:15:01,534 [INFO] Max GPU memory allocated: 1604.650M\n",
      "Training: 100%|██████████| 91/91 [03:11<00:00,  2.11s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:21<00:00,  1.56s/it]\n",
      "2025-05-02 19:17:23,509 [INFO] Validation results: {'i_r1': 0.583160800552105, 'i_r5': 0.8585231193926847, 'i_r10': 0.9337474120082816, 'i_medr': np.float64(1.0), 'i_meanr': np.float64(3.2111801242236027), 't_r1': 0.5486542443064182, 't_r5': 0.8295376121463078, 't_r10': 0.9020013802622499, 't_medr': np.float64(1.0), 't_meanr': np.float64(4.474120082815735)}\n",
      "2025-05-02 19:17:23,540 [INFO] Training epoch 1\n",
      "2025-05-02 19:17:25,118 [INFO]   step: 0 loss: 1.502 lr: 6.667e-06\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-05-02 19:17:25,121 [INFO] GPU/RAM status: RAM 5.0/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 42% Mem 1.8/3.0 Temp 73°C\n",
      "2025-05-02 19:17:40,652 [INFO]   step: 10 loss: 1.390 lr: 6.300e-06\n",
      "2025-05-02 19:17:56,125 [INFO]   step: 20 loss: 1.433 lr: 5.934e-06\n",
      "2025-05-02 19:18:11,581 [INFO]   step: 30 loss: 1.351 lr: 5.568e-06\n",
      "2025-05-02 19:18:27,044 [INFO]   step: 40 loss: 1.167 lr: 5.201e-06\n",
      "2025-05-02 19:18:42,622 [INFO]   step: 50 loss: 1.193 lr: 4.835e-06\n",
      "Training:  55%|█████▍    | 50/91 [01:19<01:03,  1.56s/it]2025-05-02 19:18:42,625 [INFO] GPU/RAM status: RAM 5.0/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 38% Mem 1.8/3.0 Temp 73°C\n",
      "2025-05-02 19:18:57,984 [INFO]   step: 60 loss: 1.276 lr: 4.469e-06\n",
      "2025-05-02 19:19:13,420 [INFO]   step: 70 loss: 1.172 lr: 4.103e-06\n",
      "2025-05-02 19:19:28,971 [INFO]   step: 80 loss: 1.247 lr: 3.736e-06\n",
      "2025-05-02 19:19:44,455 [INFO]   step: 90 loss: 1.230 lr: 3.370e-06\n",
      "Training: 100%|██████████| 91/91 [02:20<00:00,  1.56s/it]2025-05-02 19:19:44,460 [INFO] Max GPU memory allocated: 1604.650M\n",
      "Training: 100%|██████████| 91/91 [02:20<00:00,  1.55s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:21<00:00,  1.55s/it]\n",
      "2025-05-02 19:22:06,033 [INFO] Validation results: {'i_r1': 0.5921325051759835, 'i_r5': 0.8564527260179434, 'i_r10': 0.935127674258109, 'i_medr': np.float64(1.0), 'i_meanr': np.float64(3.1435472739820565), 't_r1': 0.5548654244306418, 't_r5': 0.8302277432712215, 't_r10': 0.9047619047619048, 't_medr': np.float64(1.0), 't_meanr': np.float64(4.387163561076605)}\n",
      "2025-05-02 19:22:06,067 [INFO] Training epoch 2\n",
      "2025-05-02 19:22:07,648 [INFO]   step: 0 loss: 1.225 lr: 3.333e-06\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-05-02 19:22:07,651 [INFO] GPU/RAM status: RAM 4.9/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 38% Mem 1.8/3.0 Temp 73°C\n",
      "2025-05-02 19:22:23,216 [INFO]   step: 10 loss: 1.313 lr: 2.967e-06\n",
      "2025-05-02 19:22:38,618 [INFO]   step: 20 loss: 1.077 lr: 2.601e-06\n",
      "2025-05-02 19:22:54,014 [INFO]   step: 30 loss: 1.094 lr: 2.234e-06\n",
      "2025-05-02 19:23:09,593 [INFO]   step: 40 loss: 1.199 lr: 1.868e-06\n",
      "2025-05-02 19:23:25,023 [INFO]   step: 50 loss: 1.254 lr: 1.502e-06\n",
      "Training:  55%|█████▍    | 50/91 [01:18<01:03,  1.54s/it]2025-05-02 19:23:25,027 [INFO] GPU/RAM status: RAM 5.0/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 38% Mem 1.8/3.0 Temp 73°C\n",
      "2025-05-02 19:23:40,444 [INFO]   step: 60 loss: 1.153 lr: 1.136e-06\n",
      "2025-05-02 19:23:56,060 [INFO]   step: 70 loss: 1.215 lr: 7.692e-07\n",
      "2025-05-02 19:24:11,577 [INFO]   step: 80 loss: 1.227 lr: 4.029e-07\n",
      "2025-05-02 19:24:27,036 [INFO]   step: 90 loss: 1.227 lr: 3.663e-08\n",
      "Training: 100%|██████████| 91/91 [02:20<00:00,  1.55s/it]2025-05-02 19:24:27,041 [INFO] Max GPU memory allocated: 1604.650M\n",
      "Training: 100%|██████████| 91/91 [02:20<00:00,  1.55s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:21<00:00,  1.56s/it]\n",
      "2025-05-02 19:26:48,757 [INFO] Validation results: {'i_r1': 0.5914423740510697, 'i_r5': 0.8564527260179434, 'i_r10': 0.9337474120082816, 'i_medr': np.float64(1.0), 'i_meanr': np.float64(3.142857142857143), 't_r1': 0.5548654244306418, 't_r5': 0.8309178743961353, 't_r10': 0.9033816425120773, 't_medr': np.float64(1.0), 't_meanr': np.float64(4.363699102829537)}\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Finetune instead of Train from Scratch\n",
    "# Todo: Now, try finetuning the head instead with --finetune. \n",
    "#       Set learning rate to 1e-5, weight decay to 0 and train for 3 epochs. \n",
    "#       What score do you get and how can you explain the difference to the score when training from scratch? (1 point)\n",
    "#       Try different search queries. What do you observe?\n",
    "\n",
    "train_retrieval_without_args(finetune=True, learning_rate=1e-5, weight_decay=0, epochs=3, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64660e3d-13a2-4fd9-bea9-bd22f32c3524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 19:27:17,293 [INFO] Running on device: cuda, cuda available: True\n",
      "2025-05-02 19:27:20,133 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2025-05-02 19:27:20,209 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2025-05-02 19:27:20,674 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-02 19:27:20,888 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2025-05-02 19:27:20,889 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-05-02 19:27:20,915 [INFO] Done loading retrieval head from /home/lmb/dllab2025s/public/ckpt/blip_model_retrieval_head.pth\n",
      "2025-05-02 19:27:21,165 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-02 19:27:21,166 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2025-05-02 19:27:21,167 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-02 19:27:21,168 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2025-05-02 19:27:21,168 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "2025-05-02 19:27:21,246 [INFO] GPU/RAM status: RAM 5.1/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 47% UMem 2% Mem 1.8/3.0 Temp 56°C\n",
      "2025-05-02 19:27:21,248 [INFO] Output dir: outputs/train_retrieval/2025_05_02_19_27_21\n",
      "2025-05-02 19:27:21,256 [INFO] Training epoch 0\n",
      "2025-05-02 19:27:22,848 [INFO]   step: 0 loss: 1.573 lr: 1.000e-05\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-05-02 19:27:22,852 [INFO] GPU/RAM status: RAM 5.1/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 38% Mem 1.8/3.0 Temp 61°C\n",
      "Training:   4%|▍         | 4/91 [00:06<02:14,  1.54s/it]/project/dl2025s/biswass/exercise/models/preprocessing/randaugment.py:40: RuntimeWarning: overflow encountered in scalar negative\n",
      "  offset = -low * scale\n",
      "2025-05-02 19:27:38,281 [INFO]   step: 10 loss: 1.577 lr: 9.634e-06\n",
      "2025-05-02 19:27:53,651 [INFO]   step: 20 loss: 1.569 lr: 9.267e-06\n",
      "2025-05-02 19:28:09,039 [INFO]   step: 30 loss: 1.554 lr: 8.901e-06\n",
      "2025-05-02 19:28:24,517 [INFO]   step: 40 loss: 1.548 lr: 8.535e-06\n",
      "2025-05-02 19:28:40,059 [INFO]   step: 50 loss: 1.441 lr: 8.168e-06\n",
      "Training:  55%|█████▍    | 50/91 [01:18<01:03,  1.55s/it]2025-05-02 19:28:40,063 [INFO] GPU/RAM status: RAM 5.1/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 39% Mem 1.8/3.0 Temp 71°C\n",
      "2025-05-02 19:28:55,600 [INFO]   step: 60 loss: 1.541 lr: 7.802e-06\n",
      "2025-05-02 19:29:10,945 [INFO]   step: 70 loss: 1.396 lr: 7.436e-06\n",
      "2025-05-02 19:29:26,388 [INFO]   step: 80 loss: 1.400 lr: 7.070e-06\n",
      "2025-05-02 19:29:41,917 [INFO]   step: 90 loss: 1.236 lr: 6.703e-06\n",
      "Training: 100%|██████████| 91/91 [02:20<00:00,  1.57s/it]2025-05-02 19:29:41,921 [INFO] Max GPU memory allocated: 1605.306M\n",
      "Training: 100%|██████████| 91/91 [02:20<00:00,  1.55s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:21<00:00,  1.55s/it]\n",
      "2025-05-02 19:32:03,416 [INFO] Validation results: {'i_r1': 0.5921325051759835, 'i_r5': 0.8592132505175983, 'i_r10': 0.9337474120082816, 'i_medr': np.float64(1.0), 'i_meanr': np.float64(3.197377501725328), 't_r1': 0.549344375431332, 't_r5': 0.828847481021394, 't_r10': 0.9020013802622499, 't_medr': np.float64(1.0), 't_meanr': np.float64(4.474120082815735)}\n",
      "2025-05-02 19:32:03,448 [INFO] Training epoch 1\n",
      "2025-05-02 19:32:05,058 [INFO]   step: 0 loss: 1.519 lr: 6.667e-06\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-05-02 19:32:05,062 [INFO] GPU/RAM status: RAM 5.1/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 38% Mem 1.8/3.0 Temp 73°C\n",
      "2025-05-02 19:32:20,480 [INFO]   step: 10 loss: 1.389 lr: 6.300e-06\n",
      "2025-05-02 19:32:35,881 [INFO]   step: 20 loss: 1.329 lr: 5.934e-06\n",
      "2025-05-02 19:32:51,128 [INFO]   step: 30 loss: 1.356 lr: 5.568e-06\n",
      "2025-05-02 19:33:06,460 [INFO]   step: 40 loss: 1.149 lr: 5.201e-06\n",
      "2025-05-02 19:33:21,645 [INFO]   step: 50 loss: 1.193 lr: 4.835e-06\n",
      "Training:  55%|█████▍    | 50/91 [01:18<01:02,  1.51s/it]2025-05-02 19:33:21,649 [INFO] GPU/RAM status: RAM 5.1/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 42% Mem 1.8/3.0 Temp 73°C\n",
      "2025-05-02 19:33:36,943 [INFO]   step: 60 loss: 1.170 lr: 4.469e-06\n",
      "2025-05-02 19:33:52,409 [INFO]   step: 70 loss: 1.157 lr: 4.103e-06\n",
      "2025-05-02 19:34:07,893 [INFO]   step: 80 loss: 1.268 lr: 3.736e-06\n",
      "2025-05-02 19:34:23,356 [INFO]   step: 90 loss: 1.201 lr: 3.370e-06\n",
      "Training: 100%|██████████| 91/91 [02:19<00:00,  1.56s/it]2025-05-02 19:34:23,361 [INFO] Max GPU memory allocated: 1605.306M\n",
      "Training: 100%|██████████| 91/91 [02:19<00:00,  1.54s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:21<00:00,  1.55s/it]\n",
      "2025-05-02 19:36:45,040 [INFO] Validation results: {'i_r1': 0.5928226363008972, 'i_r5': 0.8571428571428571, 'i_r10': 0.935127674258109, 'i_medr': np.float64(1.0), 'i_meanr': np.float64(3.1463077984817116), 't_r1': 0.5534851621808143, 't_r5': 0.8295376121463078, 't_r10': 0.9033816425120773, 't_medr': np.float64(1.0), 't_meanr': np.float64(4.385093167701863)}\n",
      "2025-05-02 19:36:45,104 [INFO] Training epoch 2\n",
      "2025-05-02 19:36:46,691 [INFO]   step: 0 loss: 1.242 lr: 3.333e-06\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-05-02 19:36:46,697 [INFO] GPU/RAM status: RAM 5.1/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 42% Mem 1.8/3.0 Temp 73°C\n",
      "2025-05-02 19:37:02,116 [INFO]   step: 10 loss: 1.304 lr: 2.967e-06\n",
      "2025-05-02 19:37:17,620 [INFO]   step: 20 loss: 1.066 lr: 2.601e-06\n",
      "2025-05-02 19:37:33,152 [INFO]   step: 30 loss: 1.081 lr: 2.234e-06\n",
      "2025-05-02 19:37:48,582 [INFO]   step: 40 loss: 1.222 lr: 1.868e-06\n",
      "2025-05-02 19:38:04,068 [INFO]   step: 50 loss: 1.238 lr: 1.502e-06\n",
      "Training:  55%|█████▍    | 50/91 [01:18<01:03,  1.54s/it]2025-05-02 19:38:04,073 [INFO] GPU/RAM status: RAM 5.1/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 38% Mem 1.8/3.0 Temp 73°C\n",
      "2025-05-02 19:38:19,498 [INFO]   step: 60 loss: 1.163 lr: 1.136e-06\n",
      "2025-05-02 19:38:34,959 [INFO]   step: 70 loss: 1.181 lr: 7.692e-07\n",
      "2025-05-02 19:38:50,366 [INFO]   step: 80 loss: 1.096 lr: 4.029e-07\n",
      "2025-05-02 19:39:05,798 [INFO]   step: 90 loss: 1.213 lr: 3.663e-08\n",
      "Training: 100%|██████████| 91/91 [02:20<00:00,  1.55s/it]2025-05-02 19:39:05,803 [INFO] Max GPU memory allocated: 1605.306M\n",
      "Training: 100%|██████████| 91/91 [02:20<00:00,  1.55s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:21<00:00,  1.55s/it]\n",
      "2025-05-02 19:41:27,194 [INFO] Validation results: {'i_r1': 0.5969634230503795, 'i_r5': 0.8585231193926847, 'i_r10': 0.9358178053830227, 'i_medr': np.float64(1.0), 'i_meanr': np.float64(3.1345755693581783), 't_r1': 0.5527950310559007, 't_r5': 0.8309178743961353, 't_r10': 0.904071773636991, 't_medr': np.float64(1.0), 't_meanr': np.float64(4.358178053830228)}\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Student Hyperparameter Search\n",
    "# Todo: Experiment with different hyperparameters in the random initialization setting (i.e. without finetuning). \n",
    "#       Try at least 3 new hyperparameter settings.\n",
    "#       Note the hyperparameters and the resulting image-to-text R@1 score in a table for each setting. \n",
    "#       Can you improve over the baselines? Add the table to your report. (1 point)\n",
    "\n",
    "train_retrieval_without_args(finetune=True, learning_rate=1e-5, weight_decay=1e-5, epochs=3, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4990dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 19:41:34,403 [INFO] Running on device: cuda, cuda available: True\n",
      "2025-05-02 19:41:37,273 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2025-05-02 19:41:37,357 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2025-05-02 19:41:37,827 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-02 19:41:38,044 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2025-05-02 19:41:38,045 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-05-02 19:41:38,309 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-02 19:41:38,309 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2025-05-02 19:41:38,310 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-02 19:41:38,311 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2025-05-02 19:41:38,311 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "2025-05-02 19:41:38,388 [INFO] GPU/RAM status: RAM 4.9/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 71% UMem 3% Mem 1.8/3.0 Temp 64°C\n",
      "2025-05-02 19:41:38,390 [INFO] Output dir: outputs/train_retrieval/2025_05_02_19_41_38\n",
      "2025-05-02 19:41:38,397 [INFO] Training epoch 0\n",
      "2025-05-02 19:41:40,012 [INFO]   step: 0 loss: 2.758 lr: 1.000e-05\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-05-02 19:41:40,016 [INFO] GPU/RAM status: RAM 5.0/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 42% Mem 1.8/3.0 Temp 68°C\n",
      "2025-05-02 19:41:55,524 [INFO]   step: 10 loss: 2.837 lr: 9.634e-06\n",
      "2025-05-02 19:42:11,066 [INFO]   step: 20 loss: 2.762 lr: 9.267e-06\n",
      "2025-05-02 19:42:26,560 [INFO]   step: 30 loss: 2.854 lr: 8.901e-06\n",
      "2025-05-02 19:42:42,055 [INFO]   step: 40 loss: 2.875 lr: 8.535e-06\n",
      "2025-05-02 19:42:57,608 [INFO]   step: 50 loss: 2.719 lr: 8.168e-06\n",
      "Training:  55%|█████▍    | 50/91 [01:19<01:03,  1.56s/it]2025-05-02 19:42:57,612 [INFO] GPU/RAM status: RAM 5.1/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 38% Mem 1.8/3.0 Temp 71°C\n",
      "2025-05-02 19:43:13,111 [INFO]   step: 60 loss: 2.829 lr: 7.802e-06\n",
      "2025-05-02 19:43:28,627 [INFO]   step: 70 loss: 2.643 lr: 7.436e-06\n",
      "2025-05-02 19:43:44,184 [INFO]   step: 80 loss: 2.751 lr: 7.070e-06\n",
      "2025-05-02 19:43:59,677 [INFO]   step: 90 loss: 2.743 lr: 6.703e-06\n",
      "Training: 100%|██████████| 91/91 [02:21<00:00,  1.57s/it]2025-05-02 19:43:59,683 [INFO] Max GPU memory allocated: 1605.306M\n",
      "Training: 100%|██████████| 91/91 [02:21<00:00,  1.55s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:21<00:00,  1.56s/it]\n",
      "2025-05-02 19:46:21,701 [INFO] Validation results: {'i_r1': 0.0, 'i_r5': 0.00759144237405107, 'i_r10': 0.015873015873015872, 'i_medr': np.float64(406.0), 'i_meanr': np.float64(496.7129054520359), 't_r1': 0.0006901311249137336, 't_r5': 0.013112491373360938, 't_r10': 0.022084195997239476, 't_medr': np.float64(396.0), 't_meanr': np.float64(487.0124223602484)}\n",
      "2025-05-02 19:46:21,735 [INFO] Training epoch 1\n",
      "2025-05-02 19:46:23,330 [INFO]   step: 0 loss: 2.615 lr: 6.667e-06\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-05-02 19:46:23,333 [INFO] GPU/RAM status: RAM 5.2/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 42% Mem 1.8/3.0 Temp 73°C\n",
      "2025-05-02 19:46:38,787 [INFO]   step: 10 loss: 2.654 lr: 6.300e-06\n",
      "2025-05-02 19:46:54,198 [INFO]   step: 20 loss: 2.704 lr: 5.934e-06\n",
      "2025-05-02 19:47:09,704 [INFO]   step: 30 loss: 2.571 lr: 5.568e-06\n",
      "2025-05-02 19:47:25,109 [INFO]   step: 40 loss: 2.620 lr: 5.201e-06\n",
      "2025-05-02 19:47:40,609 [INFO]   step: 50 loss: 2.610 lr: 4.835e-06\n",
      "Training:  55%|█████▍    | 50/91 [01:18<01:03,  1.55s/it]2025-05-02 19:47:40,612 [INFO] GPU/RAM status: RAM 5.2/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 37% Mem 1.8/3.0 Temp 73°C\n",
      "2025-05-02 19:47:56,063 [INFO]   step: 60 loss: 2.590 lr: 4.469e-06\n",
      "2025-05-02 19:48:11,416 [INFO]   step: 70 loss: 2.659 lr: 4.103e-06\n",
      "2025-05-02 19:48:26,927 [INFO]   step: 80 loss: 2.511 lr: 3.736e-06\n",
      "2025-05-02 19:48:42,444 [INFO]   step: 90 loss: 2.351 lr: 3.370e-06\n",
      "Training: 100%|██████████| 91/91 [02:20<00:00,  1.57s/it]2025-05-02 19:48:42,448 [INFO] Max GPU memory allocated: 1605.306M\n",
      "Training: 100%|██████████| 91/91 [02:20<00:00,  1.55s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:21<00:00,  1.56s/it]\n",
      "2025-05-02 19:51:04,309 [INFO] Validation results: {'i_r1': 0.0013802622498274672, 'i_r5': 0.013802622498274672, 'i_r10': 0.033126293995859216, 'i_medr': np.float64(249.0), 'i_meanr': np.float64(371.5507246376812), 't_r1': 0.003450655624568668, 't_r5': 0.023464458247066944, 't_r10': 0.04071773636991028, 't_medr': np.float64(246.0), 't_meanr': np.float64(369.86542443064184)}\n",
      "2025-05-02 19:51:04,341 [INFO] Training epoch 2\n",
      "2025-05-02 19:51:05,913 [INFO]   step: 0 loss: 2.560 lr: 3.333e-06\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-05-02 19:51:05,917 [INFO] GPU/RAM status: RAM 5.2/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 42% Mem 1.8/3.0 Temp 73°C\n",
      "2025-05-02 19:51:22,114 [INFO]   step: 10 loss: 2.638 lr: 2.967e-06\n",
      "2025-05-02 19:51:37,619 [INFO]   step: 20 loss: 2.275 lr: 2.601e-06\n",
      "2025-05-02 19:51:53,141 [INFO]   step: 30 loss: 2.548 lr: 2.234e-06\n",
      "2025-05-02 19:52:08,625 [INFO]   step: 40 loss: 2.514 lr: 1.868e-06\n",
      "2025-05-02 19:52:24,020 [INFO]   step: 50 loss: 2.508 lr: 1.502e-06\n",
      "Training:  55%|█████▍    | 50/91 [01:19<01:02,  1.53s/it]2025-05-02 19:52:24,023 [INFO] GPU/RAM status: RAM 5.0/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 37% Mem 1.8/3.0 Temp 73°C\n",
      "2025-05-02 19:52:39,429 [INFO]   step: 60 loss: 2.409 lr: 1.136e-06\n",
      "2025-05-02 19:52:54,880 [INFO]   step: 70 loss: 2.483 lr: 7.692e-07\n",
      "2025-05-02 19:53:10,312 [INFO]   step: 80 loss: 2.477 lr: 4.029e-07\n",
      "2025-05-02 19:53:25,720 [INFO]   step: 90 loss: 2.446 lr: 3.663e-08\n",
      "Training: 100%|██████████| 91/91 [02:21<00:00,  1.55s/it]2025-05-02 19:53:25,725 [INFO] Max GPU memory allocated: 1605.306M\n",
      "Training: 100%|██████████| 91/91 [02:21<00:00,  1.55s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:24<00:00,  1.58s/it]\n",
      "2025-05-02 19:55:50,129 [INFO] Validation results: {'i_r1': 0.0027605244996549345, 'i_r5': 0.020703933747412008, 'i_r10': 0.043478260869565216, 'i_medr': np.float64(206.0), 'i_meanr': np.float64(333.62525879917183), 't_r1': 0.006211180124223602, 't_r5': 0.025534851621808144, 't_r10': 0.05314009661835749, 't_medr': np.float64(208.0), 't_meanr': np.float64(334.86680469289166)}\n"
     ]
    }
   ],
   "source": [
    "train_retrieval_without_args(finetune=False, learning_rate=1e-5, weight_decay=1e-5, epochs=3, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c50ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 19:57:24,928 [INFO] Running on device: cuda, cuda available: True\n",
      "2025-05-02 19:57:27,740 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2025-05-02 19:57:27,835 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2025-05-02 19:57:28,312 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-02 19:57:28,544 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2025-05-02 19:57:28,544 [INFO] Done loading checkpoint from /home/lmb/dllab2025s/public/ckpt/blip_model_base.pth\n",
      "2025-05-02 19:57:28,573 [INFO] Done loading retrieval head from /home/lmb/dllab2025s/public/ckpt/blip_model_retrieval_head.pth\n",
      "2025-05-02 19:57:28,839 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-02 19:57:28,839 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2025-05-02 19:57:28,840 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-02 19:57:28,840 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2025-05-02 19:57:28,841 [INFO] Load dataset from /home/lmb/dllab2025s/public/data/VOCdevkit/VOC2012\n",
      "2025-05-02 19:57:28,926 [INFO] GPU/RAM status: RAM 5.2/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 69% UMem 3% Mem 1.8/3.0 Temp 43°C\n",
      "2025-05-02 19:57:28,929 [INFO] Output dir: outputs/train_retrieval/2025_05_02_19_57_28\n",
      "2025-05-02 19:57:28,935 [INFO] Training epoch 0\n",
      "2025-05-02 19:57:30,531 [INFO]   step: 0 loss: 2.128 lr: 1.000e-05\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-05-02 19:57:30,535 [INFO] GPU/RAM status: RAM 5.2/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 42% Mem 1.8/3.0 Temp 49°C\n",
      "2025-05-02 19:57:45,812 [INFO]   step: 10 loss: 2.129 lr: 9.634e-06\n",
      "2025-05-02 19:58:01,158 [INFO]   step: 20 loss: 2.119 lr: 9.267e-06\n",
      "2025-05-02 19:58:16,540 [INFO]   step: 30 loss: 2.121 lr: 8.901e-06\n",
      "2025-05-02 19:58:31,894 [INFO]   step: 40 loss: 2.116 lr: 8.535e-06\n",
      "2025-05-02 19:58:47,207 [INFO]   step: 50 loss: 2.108 lr: 8.168e-06\n",
      "Training:  55%|█████▍    | 50/91 [01:18<01:02,  1.51s/it]2025-05-02 19:58:47,210 [INFO] GPU/RAM status: RAM 5.2/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 38% Mem 1.8/3.0 Temp 69°C\n",
      "2025-05-02 19:59:02,865 [INFO]   step: 60 loss: 2.092 lr: 7.802e-06\n",
      "2025-05-02 19:59:19,338 [INFO]   step: 70 loss: 2.024 lr: 7.436e-06\n",
      "2025-05-02 19:59:36,467 [INFO]   step: 80 loss: 2.026 lr: 7.070e-06\n",
      "2025-05-02 19:59:53,654 [INFO]   step: 90 loss: 1.922 lr: 6.703e-06\n",
      "Training: 100%|██████████| 91/91 [02:24<00:00,  1.73s/it]2025-05-02 19:59:53,658 [INFO] Max GPU memory allocated: 1605.306M\n",
      "Training: 100%|██████████| 91/91 [02:24<00:00,  1.59s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:23<00:00,  1.57s/it]\n",
      "2025-05-02 20:02:16,888 [INFO] Validation results: {'i_r1': 0.5741890959282263, 'i_r5': 0.8461007591442374, 'i_r10': 0.9316770186335404, 'i_medr': np.float64(1.0), 'i_meanr': np.float64(3.3609385783298826), 't_r1': 0.5438233264320221, 't_r5': 0.8274672187715666, 't_r10': 0.8999309868875086, 't_medr': np.float64(1.0), 't_meanr': np.float64(4.503105590062112)}\n",
      "2025-05-02 20:02:16,920 [INFO] Training epoch 1\n",
      "2025-05-02 20:02:18,537 [INFO]   step: 0 loss: 2.072 lr: 6.667e-06\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-05-02 20:02:18,541 [INFO] GPU/RAM status: RAM 5.6/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 42% Mem 1.8/3.0 Temp 73°C\n",
      "2025-05-02 20:02:34,617 [INFO]   step: 10 loss: 1.977 lr: 6.300e-06\n",
      "2025-05-02 20:02:50,119 [INFO]   step: 20 loss: 1.973 lr: 5.934e-06\n",
      "2025-05-02 20:03:05,586 [INFO]   step: 30 loss: 2.001 lr: 5.568e-06\n",
      "2025-05-02 20:03:20,959 [INFO]   step: 40 loss: 1.849 lr: 5.201e-06\n",
      "2025-05-02 20:03:36,447 [INFO]   step: 50 loss: 1.893 lr: 4.835e-06\n",
      "Training:  55%|█████▍    | 50/91 [01:19<01:03,  1.54s/it]2025-05-02 20:03:36,450 [INFO] GPU/RAM status: RAM 5.4/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 38% Mem 1.8/3.0 Temp 73°C\n",
      "2025-05-02 20:03:51,822 [INFO]   step: 60 loss: 1.844 lr: 4.469e-06\n",
      "2025-05-02 20:04:07,260 [INFO]   step: 70 loss: 1.863 lr: 4.103e-06\n",
      "2025-05-02 20:04:22,685 [INFO]   step: 80 loss: 1.923 lr: 3.736e-06\n",
      "2025-05-02 20:04:38,074 [INFO]   step: 90 loss: 1.880 lr: 3.370e-06\n",
      "Training: 100%|██████████| 91/91 [02:21<00:00,  1.54s/it]2025-05-02 20:04:38,079 [INFO] Max GPU memory allocated: 1605.306M\n",
      "Training: 100%|██████████| 91/91 [02:21<00:00,  1.55s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:25<00:00,  1.60s/it]\n",
      "2025-05-02 20:07:03,676 [INFO] Validation results: {'i_r1': 0.5914423740510697, 'i_r5': 0.8557625948930296, 'i_r10': 0.9358178053830227, 'i_medr': np.float64(1.0), 'i_meanr': np.float64(3.198757763975155), 't_r1': 0.5514147688060732, 't_r5': 0.8309178743961353, 't_r10': 0.9020013802622499, 't_medr': np.float64(1.0), 't_meanr': np.float64(4.3940648723257425)}\n",
      "2025-05-02 20:07:03,744 [INFO] Training epoch 2\n",
      "2025-05-02 20:07:05,314 [INFO]   step: 0 loss: 1.911 lr: 3.333e-06\n",
      "Training:   0%|          | 0/91 [00:01<?, ?it/s]2025-05-02 20:07:05,318 [INFO] GPU/RAM status: RAM 5.4/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 42% Mem 1.8/3.0 Temp 71°C\n",
      "2025-05-02 20:07:20,855 [INFO]   step: 10 loss: 1.941 lr: 2.967e-06\n",
      "2025-05-02 20:07:36,363 [INFO]   step: 20 loss: 1.876 lr: 2.601e-06\n",
      "2025-05-02 20:07:51,863 [INFO]   step: 30 loss: 1.797 lr: 2.234e-06\n",
      "2025-05-02 20:08:07,355 [INFO]   step: 40 loss: 1.982 lr: 1.868e-06\n",
      "2025-05-02 20:08:22,782 [INFO]   step: 50 loss: 1.896 lr: 1.502e-06\n",
      "Training:  55%|█████▍    | 50/91 [01:19<01:03,  1.54s/it]2025-05-02 20:08:22,785 [INFO] GPU/RAM status: RAM 5.5/14.6 GPU NVIDIA GeForce GTX 1060 3GB Util 100% UMem 37% Mem 1.8/3.0 Temp 72°C\n",
      "2025-05-02 20:08:38,301 [INFO]   step: 60 loss: 1.836 lr: 1.136e-06\n",
      "2025-05-02 20:08:53,718 [INFO]   step: 70 loss: 1.850 lr: 7.692e-07\n",
      "2025-05-02 20:09:09,195 [INFO]   step: 80 loss: 1.818 lr: 4.029e-07\n",
      "2025-05-02 20:09:24,633 [INFO]   step: 90 loss: 1.886 lr: 3.663e-08\n",
      "Training: 100%|██████████| 91/91 [02:20<00:00,  1.56s/it]2025-05-02 20:09:24,638 [INFO] Max GPU memory allocated: 1605.306M\n",
      "Training: 100%|██████████| 91/91 [02:20<00:00,  1.55s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [02:21<00:00,  1.56s/it]\n",
      "2025-05-02 20:11:46,373 [INFO] Validation results: {'i_r1': 0.5873015873015873, 'i_r5': 0.8571428571428571, 'i_r10': 0.9323671497584541, 'i_medr': np.float64(1.0), 'i_meanr': np.float64(3.1718426501035197), 't_r1': 0.5534851621808143, 't_r5': 0.8309178743961353, 't_r10': 0.9013112491373361, 't_medr': np.float64(1.0), 't_meanr': np.float64(4.380952380952381)}\n"
     ]
    }
   ],
   "source": [
    "train_retrieval_without_args(finetune=True, learning_rate=1e-5, weight_decay=1e-3, epochs=3, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de0659-9b4b-4875-815a-b58a82cfc8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Visualize Top 10 results for a search query.\n",
    "\n",
    "from search_retrieval import get_top10\n",
    "\n",
    "search_query = \"a picture of a plane\"\n",
    "dict_top10 = get_top10(eval_ckpt=None, query = search_query)\n",
    "\n",
    "from PIL import Image\n",
    "for i in range(len(dict_top10[\"id\"])):\n",
    "    image_pil = Image.open(dict_top10[\"fname\"][i])\n",
    "    display(image_pil)\n",
    "    print(f\"Sim. Score: {dict_top10['sim'][i]}\")\n",
    "    print(f\"Caption: {dict_top10['caption'][i]}\")\n",
    "    #print(f\"Name: {dict_top10['name'][i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
